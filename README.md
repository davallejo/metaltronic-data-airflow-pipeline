# ğŸ­ Pipeline ETL Metaltronic S.A.

**Pipeline de datos para empresa metalmecÃ¡nica ecuatoriana**

[![Python](https://img.shields.io/badge/python-v3.9+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)
[![Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=Apache%20Airflow&logoColor=white)](https://airflow.apache.org/)
[![PostgreSQL](https://img.shields.io/badge/postgresql-%23316192.svg?style=flat&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-%234ea94b.svg?style=flat&logo=mongodb&logoColor=white)](https://www.mongodb.com/)

## ğŸ“‹ DescripciÃ³n del Proyecto

Sistema ETL (Extract, Transform, Load) desarrollado para **Metaltronic S.A.**, empresa metalmecÃ¡nica ubicada en Ambato, Tungurahua, Ecuador. El pipeline procesa diariamente datos de ventas, inventario y logs operacionales para generar insights de negocio.

### ğŸ¯ Objetivo
Automatizar el procesamiento de datos transaccionales y generar reportes analÃ­ticos que permitan:
- Monitorear el desempeÃ±o de ventas diarias
- Optimizar la gestiÃ³n de inventario
- Analizar patrones de comportamiento del sistema

## ğŸ—ï¸ Arquitectura del Sistema

```mermaid
graph TB
    subgraph "Fuentes de Datos"
        A[PostgreSQL<br/>Ventas & Inventario]
        B[MongoDB<br/>Logs del Sistema]
    end
    
    subgraph "Pipeline ETL - Apache Airflow"
        C[Extract<br/>ExtracciÃ³n]
        D[Transform<br/>TransformaciÃ³n]
        E[Load<br/>Carga]
    end
    
    subgraph "Destinos AnalÃ­ticos"
        F[PostgreSQL<br/>Data Warehouse]
        G[MongoDB<br/>Reportes de Calidad]
    end
    
    A --> C
    B --> C
    C --> D
    D --> E
    E --> F
    E --> G
```

## ğŸ› ï¸ Stack TecnolÃ³gico

### Lenguajes y Frameworks
- **Python 3.9+**: Lenguaje principal para ETL
- **SQL**: Consultas y modelado de datos
- **Pandas**: ManipulaciÃ³n y anÃ¡lisis de datos
- **SQLAlchemy**: ORM para bases de datos relacionales

### Bases de Datos
- **PostgreSQL 13**: Base de datos transaccional y data warehouse
- **MongoDB 5.0**: Almacenamiento de logs y documentos no estructurados

### Herramientas ETL y OrquestaciÃ³n
- **Apache Airflow 2.7**: OrquestaciÃ³n del pipeline
- **Docker & Docker Compose**: ContainerizaciÃ³n y despliegue

### Plataformas Cloud (Simuladas Localmente)
- **Almacenamiento**: SimulaciÃ³n de AWS S3 con volÃºmenes Docker
- **Procesamiento**: Contenedores que simulan servicios cloud

## ğŸ“ Estructura del Proyecto

```
metaltronic-data-pipeline/
â”œâ”€â”€ ğŸ“„ README.md                    # DocumentaciÃ³n principal
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # ConfiguraciÃ³n de contenedores
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Imagen personalizada Airflow
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencias Python
â”œâ”€â”€ ğŸ“„ .env                        # Variables de entorno
â”œâ”€â”€ ğŸ“„ .gitignore                  # Archivos ignorados por Git
â”œâ”€â”€ ğŸ“‚ sql/
â”‚   â”œâ”€â”€ ğŸ“„ init_postgres.sql       # Datos iniciales PostgreSQL
â”‚   â””â”€â”€ ğŸ“„ init_mongo.js           # Datos iniciales MongoDB
â”œâ”€â”€ ğŸ“‚ dags/
â”‚   â””â”€â”€ ğŸ“„ metaltronic_etl_dag.py  # DAG principal de Airflow
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ extract.py              # MÃ³dulo de extracciÃ³n
â”‚   â”œâ”€â”€ ğŸ“„ transform.py            # MÃ³dulo de transformaciÃ³n
â”‚   â””â”€â”€ ğŸ“„ load.py                 # MÃ³dulo de carga
â”œâ”€â”€ ğŸ“‚ config/
â”‚   â””â”€â”€ ğŸ“„ database.py             # ConfiguraciÃ³n de conexiones
â””â”€â”€ ğŸ“‚ data/
    â”œâ”€â”€ ğŸ“‚ raw/                    # Datos sin procesar
    â””â”€â”€ ğŸ“‚ processed/              # Datos transformados
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
- Docker Desktop 4.0+ instalado
- Git para clonar el repositorio
- 8GB RAM disponible (recomendado)
- Puertos disponibles: 5432, 27017, 8080, 6379

### 1. Clonar el Repositorio
```bash
git clone https://github.com/tu-usuario/metaltronic-data-pipeline.git
cd metaltronic-data-pipeline
```

### 2. Configurar Variables de Entorno
```bash
# El archivo .env ya estÃ¡ incluido con valores por defecto
# Opcional: personalizar credenciales si es necesario
cp .env .env.local
```

### 3. Construir y Ejecutar los Contenedores
```bash
# Construir las imÃ¡genes
docker-compose build

# Ejecutar en segundo plano
docker-compose up -d

# Verificar que todos los servicios estÃ©n corriendo
docker-compose ps
```

### 4. Verificar la InstalaciÃ³n
```bash
# Verificar logs de Airflow
docker-compose logs airflow-webserver

# Verificar conexiÃ³n a PostgreSQL
docker-compose exec postgres psql -U metaltronic_user -d metaltronic_db -c "\dt ventas.*"

# Verificar conexiÃ³n a MongoDB
docker-compose exec mongodb mongo -u mongo_user -p mongo_pass --authenticationDatabase admin
```

## ğŸ® Uso del Sistema

### Acceso a la Interfaz Web de Airflow
1. Abrir navegador en: http://localhost:8080
2. **Usuario**: `admin`
3. **ContraseÃ±a**: `admin123`

### Ejecutar el Pipeline ETL

#### EjecuciÃ³n Manual
1. En la interfaz de Airflow, buscar el DAG: `metaltronic_etl_pipeline`
2. Activar el DAG con el toggle
3. Hacer clic en "Trigger DAG" para ejecutar manualmente

#### EjecuciÃ³n Programada
- El pipeline se ejecuta automÃ¡ticamente todos los dÃ­as a las 6:00 AM
- Procesa los datos del dÃ­a anterior

### Monitorear la EjecuciÃ³n
```bash
# Ver logs del pipeline
docker-compose logs -f airflow-scheduler

# Ver logs especÃ­ficos de una tarea
docker-compose exec airflow-webserver airflow tasks log metaltronic_etl_pipeline extract_data 2024-01-15
```

## ğŸ§ª Pruebas y ValidaciÃ³n

### 1. Verificar Datos de Origen
```sql
-- Conectar a PostgreSQL
docker-compose exec postgres psql -U metaltronic_user -d metaltronic_db

-- Verificar datos de ventas
SELECT COUNT(*) FROM ventas.transacciones;
SELECT COUNT(*) FROM ventas.detalle_ventas;
SELECT COUNT(*) FROM inventario.productos;
```

```javascript
// Conectar a MongoDB
docker-compose exec mongodb mongo -u mongo_user -p mongo_pass --authenticationDatabase admin

use metaltronic_mongo
db.logs_ventas.count()
db.sesiones_usuario.count()
```

### 2. Ejecutar Pipeline Completo
```bash
# Ejecutar DAG especÃ­fico para una fecha
docker-compose exec airflow-webserver airflow dags trigger metaltronic_etl_pipeline

# Monitorear estado
docker-compose exec airflow-webserver airflow dags state metaltronic_etl_pipeline 2024-01-15
```

### 3. Validar Resultados
```sql
-- Verificar datos procesados en PostgreSQL
SELECT * FROM analytics.resumen_ventas_diario ORDER BY fecha_resumen DESC LIMIT 5;
SELECT * FROM analytics.analisis_inventario WHERE performance = 'Alto' LIMIT 10;
```

### 4. Casos de Prueba
- âœ… **ExtracciÃ³n**: Verificar que se extraigan datos de ambas fuentes
- âœ… **TransformaciÃ³n**: Validar cÃ¡lculos de mÃ©tricas de negocio
- âœ… **Carga**: Confirmar inserciÃ³n en tablas de destino
- âœ… **Calidad**: Revisar reportes de calidad de datos

## ğŸ“Š Datos y MÃ©tricas Generadas

### Resumen Diario de Ventas
- Total de ventas por dÃ­a
- NÃºmero de transacciones
- Productos mÃ¡s vendidos
- Clientes mÃ¡s frecuentes
- Promedio de ticket de compra

### AnÃ¡lisis de Inventario
- RotaciÃ³n de inventario por producto
- DÃ­as de stock disponible
- Productos con bajo stock
- Performance de ventas por categorÃ­a

### Reportes de Calidad
- Completitud de datos
- Valores duplicados
- MÃ©tricas de procesamiento
- Logs de errores y advertencias

## ğŸ”§ Comandos Ãštiles

### GestiÃ³n de Contenedores
```bash
# Detener todos los servicios
docker-compose down

# Reiniciar un servicio especÃ­fico
docker-compose restart airflow-webserver

# Ver logs en tiempo real
docker-compose logs -f [nombre-servicio]

# Limpiar volÃºmenes (CUIDADO: borra todos los datos)
docker-compose down -v
```

### GestiÃ³n de Airflow
```bash
# Reiniciar el scheduler
docker-compose exec airflow-scheduler airflow scheduler

# Listar DAGs
docker-compose exec airflow-webserver airflow dags list

# Pausar/despausar un DAG
docker-compose exec airflow-webserver airflow dags pause metaltronic_etl_pipeline
docker-compose exec airflow-webserver airflow dags unpause metaltronic_etl_pipeline
```

### Acceso a Bases de Datos
```bash
# PostgreSQL
docker-compose exec postgres psql -U metaltronic_user -d metaltronic_db

# MongoDB
docker-compose exec mongodb mongo -u mongo_user -p mongo_pass --authenticationDatabase admin
```

## ğŸ› SoluciÃ³n de Problemas

### Problemas Comunes

#### Error: Puerto ya en uso
```bash
# Verificar puertos ocupados
netstat -tulpn | grep :8080
# Cambiar puerto en docker-compose.yml o liberar puerto
```

#### Error: Falta de memoria
```bash
# Verificar uso de memoria
docker stats
# Incrementar memoria de Docker Desktop
```

#### Error: ConexiÃ³n a base de datos
```bash
# Verificar estado de contenedores
docker-compose ps
# Revisar logs de la base de datos
docker-compose logs postgres
docker-compose logs mongodb
```

### Logs de DepuraciÃ³n
```bash
# Logs detallados de Airflow
docker-compose exec airflow-webserver airflow config list
docker-compose logs airflow-webserver | grep ERROR

# Logs de pipeline
tail -f data/processed/*.log
```

## ğŸš¦ Monitoreo y Alertas

### MÃ©tricas Clave
- â±ï¸ **Tiempo de ejecuciÃ³n**: < 15 minutos por pipeline completo
- ğŸ“Š **Tasa de Ã©xito**: > 95% de ejecuciones exitosas
- ğŸ’¾ **Volumen de datos**: ~1000-5000 registros diarios
- ğŸ”„ **Frecuencia**: EjecuciÃ³n diaria automÃ¡tica

### Alertas Configuradas
- âŒ Falla en extracciÃ³n de datos
- âš ï¸ Datos faltantes o inconsistentes
- ğŸ• Pipeline tardando mÃ¡s de 30 minutos
- ğŸ’¾ Espacio en disco bajo (< 2GB disponible)

## ğŸ‘¥ ContribuciÃ³n y Desarrollo

### ConfiguraciÃ³n de Desarrollo
```bash
# Clonar y configurar entorno de desarrollo
git clone [repo-url]
cd metaltronic-data-pipeline

# Crear rama de desarrollo
git checkout -b feature/nueva-funcionalidad

# Instalar dependencias locales (opcional)
pip install -r requirements.txt
```

### Convenciones de CÃ³digo
- **Python**: Seguir PEP 8
- **SQL**: Usar UPPERCASE para palabras clave
- **Git**: Commits descriptivos en espaÃ±ol
- **DocumentaciÃ³n**: Comentarios en espaÃ±ol

### Testing
```bash
# Ejecutar tests unitarios (cuando estÃ©n disponibles)
pytest tests/

# Validar sintaxis SQL
docker-compose exec postgres psql -U metaltronic_user -d metaltronic_db -f sql/test_queries.sql
```

## ğŸ“œ Licencia y Contacto

### Empresa
**Metaltronic S.A.**
- ğŸ“ Ambato, Tungurahua, Ecuador
- ğŸ“§ info@metaltronic.com
- ğŸŒ www.metaltronic.com.ec

### Equipo de Desarrollo
- **Data Engineering Team**
- ğŸ“§ data@metaltronic.com
- ğŸ› Issues: [GitHub Issues](https://github.com/tu-usuario/metaltronic-data-pipeline/issues)

### Licencia
Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

**âš¡ Â¡Pipeline listo para procesar datos metalmecÃ¡nicos ecuatorianos!**

*Desarrollado con â¤ï¸ por el equipo de IngenierÃ­a de Datos de Metaltronic S.A.*
